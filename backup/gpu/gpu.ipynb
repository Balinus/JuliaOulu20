{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU (local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's check if there is a GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDAdrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDevice(0): GeForce GT 1030"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CuDevice(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = rand(1000,1000), rand(1000,1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move these arrays to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CuArrays\n",
    "@assert CuArrays.functional() # if this fails your GPU isn't recognized correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agpu, Bgpu = CuArray(A), CuArray(B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuArray{Float64,2,Nothing}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(Agpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much faster is a simple matmul on the GPU? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*B (cpu)\n",
      "  12.731 ms (2 allocations: 7.63 MiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"A*B (cpu)\")\n",
    "@btime $A * $B;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*B (gpu)\n",
      "  2.933 μs (10 allocations: 416 bytes)\n"
     ]
    }
   ],
   "source": [
    "println(\"A*B (gpu)\")\n",
    "@btime $Agpu * $Bgpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's at least 3 orders of magnitude faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory\n",
    "Agpu, Bgpu = nothing, nothing\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result of the multiplication lives on the GPU as well and needs to be pulled back to main memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agpu, Bgpu = CuArray(A), CuArray(B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cgpu = Agpu * Bgpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Cgpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Matrix(Cgpu); # move to cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to move the `CuArray` back to main memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime Matrix($Cgpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory\n",
    "Agpu, Bgpu, Cgpu = nothing, nothing, nothing\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: CuArrays.jl did not find libcudnn. Some functionality will not be available.\n",
      "└ @ Flux C:\\Users\\carsten\\.julia\\packages\\Flux\\2i5P1\\src\\Flux.jl:58\n"
     ]
    }
   ],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(0.01)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "    Dense(1000, 100),\n",
    "    Dense(100, 10),\n",
    "    Dense(10, 5),\n",
    "    Dense(5, 2),\n",
    "    softmax # normalize output neurons\n",
    "    )\n",
    "\n",
    "data = rand(1000, 1000); # fake data\n",
    "labels = fill(0.5, 2, 1000); # fake data\n",
    "\n",
    "loss(x, y) = sum(Flux.mse(m(x), y)) # mean squared error\n",
    "opt = Descent(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.314975 seconds (5.02 M allocations: 110.066 MiB, 1.12% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, Flux.params(m), [(data,labels)], opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the network on the GPU instead! It's as simple as `|> gpu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1411200080598672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1411200080598672"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 |> sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(0.01)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move the model to the gpu\n",
    "m = Chain(\n",
    "    Dense(1000, 100),\n",
    "    Dense(100, 10),\n",
    "    Dense(10, 5),\n",
    "    Dense(5, 2),\n",
    "    softmax\n",
    "    ) |> gpu\n",
    "\n",
    "# move data to the gpu\n",
    "data = rand(1000, 1000) |> gpu;\n",
    "labels = fill(0.5, 2, 1000) |> gpu;\n",
    "\n",
    "loss(x, y) = sum(Flux.mse(m(x), y))\n",
    "opt = Descent(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain{Tuple{Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},typeof(softmax)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006236 seconds (3.80 k allocations: 167.000 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, Flux.params(m), [(data,labels)], opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is about **two orders of magnitude faster** on the GPU in this case!\n",
    "\n",
    "Now that our model is trained, let's feed it some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: cannot take the CPU address of a CuArrays.CuArray{Float32,2,Nothing}",
     "output_type": "error",
     "traceback": [
      "ArgumentError: cannot take the CPU address of a CuArrays.CuArray{Float32,2,Nothing}",
      "",
      "Stacktrace:",
      " [1] unsafe_convert(::Type{Ptr{Float32}}, ::CuArrays.CuArray{Float32,2,Nothing}) at C:\\Users\\carsten\\.julia\\packages\\CuArrays\\AIMph\\src\\array.jl:211",
      " [2] gemv!(::Char, ::Bool, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Float32,1}, ::Bool, ::Array{Float32,1}) at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\LinearAlgebra\\src\\blas.jl:587",
      " [3] gemv!(::Array{Float32,1}, ::Char, ::CuArrays.CuArray{Float32,2,Nothing}, ::Array{Float32,1}, ::Bool, ::Bool) at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\LinearAlgebra\\src\\matmul.jl:463",
      " [4] mul! at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\LinearAlgebra\\src\\matmul.jl:66 [inlined]",
      " [5] mul! at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\LinearAlgebra\\src\\matmul.jl:203 [inlined]",
      " [6] * at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.3\\LinearAlgebra\\src\\matmul.jl:47 [inlined]",
      " [7] (::Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}})(::Array{Float32,1}) at C:\\Users\\carsten\\.julia\\packages\\Flux\\2i5P1\\src\\layers\\basic.jl:102",
      " [8] Dense at C:\\Users\\carsten\\.julia\\packages\\Flux\\2i5P1\\src\\layers\\basic.jl:113 [inlined]",
      " [9] (::Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}})(::Array{Float64,1}) at C:\\Users\\carsten\\.julia\\packages\\Flux\\2i5P1\\src\\layers\\basic.jl:116",
      " [10] applychain at C:\\Users\\carsten\\.julia\\packages\\Flux\\2i5P1\\src\\layers\\basic.jl:30 [inlined]",
      " [11] (::Chain{Tuple{Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},Dense{typeof(identity),CuArrays.CuArray{Float32,2,Nothing},CuArrays.CuArray{Float32,1,Nothing}},typeof(softmax)}})(::Array{Float64,1}) at C:\\Users\\carsten\\.julia\\packages\\Flux\\2i5P1\\src\\layers\\basic.jl:32",
      " [12] top-level scope at In[15]:1"
     ]
    }
   ],
   "source": [
    "m(rand(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. Since our model lives on the GPU we can't feed it with data living in main memory. We must move our model back to the CPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(1000, 100), Dense(100, 10), Dense(10, 5), Dense(5, 2), softmax)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_cpu = m |> cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain{Tuple{Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(m_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float32,1}:\n",
       " 0.5463516 \n",
       " 0.45364842"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_cpu(rand(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU (remote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start a worker on a gpu node of a supercomputer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs([(\"cbauer17@gpu2\", 1)]; exename=`/projects/ag-trebst/bauer/bin/julia-1.3.1/bin/julia`, exeflags=`--project=/projects/ag-trebst/bauer/JuliaOulu20/backup/gpu`, dir=\"/projects/ag-trebst/bauer/JuliaOulu20/backup/gpu\", tunnel=true)\n",
    "@fetch gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (exename=`nice -19 /home/bauer/bin/julia-1.3.1/bin/julia --project=/home/bauer/JuliaOulu20`, dir=\"/home/bauer\")\n",
    "addprocs([(\"l94\", :auto)]; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs([(\"cbauer17@gpu2\", 1)]; exename=`/projects/ag-trebst/bauer/bin/julia-1.3.1/bin/julia`, dir=`/projects/ag-trebst/bauer`, tunnel=true)\n",
    "@fetch gethostname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the GPU name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using CUDAdrv\n",
    "@fetch CUDAdrv.name(CuDevice(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using CuArrays, BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch begin\n",
    "    A, B = rand(1000,1000), rand(1000,1000);\n",
    "    Agpu, Bgpu = CuArray(A), CuArray(B);\n",
    "    \n",
    "    println(\"Move array CPU -> GPU\")\n",
    "    @btime CuArray($A);\n",
    "    \n",
    "    println(\"A*B (cpu)\")\n",
    "    @btime $A * $B;\n",
    "\n",
    "    println(\"A*B (gpu)\")\n",
    "    @btime $Agpu * $Bgpu;\n",
    "    \n",
    "    \n",
    "    println(\"Move array GPU -> CPU\")\n",
    "    Cgpu = Agpu * Bgpu\n",
    "    @btime Array($Cgpu);\n",
    "    \n",
    "    nothing\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
