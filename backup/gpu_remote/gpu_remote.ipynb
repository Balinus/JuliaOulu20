{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU (remote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start a worker on a gpu node of a supercomputer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs([(\"cbauer17@gpu2\", 1)]; exename=`/projects/ag-trebst/bauer/bin/julia-1.3.1/bin/julia`, exeflags=`--project=/projects/ag-trebst/bauer/JuliaOulu20/backup/gpu_remote`, dir=\"/projects/ag-trebst/bauer/JuliaOulu20/backup/gpu_remote\", tunnel=true)\n",
    "@fetch gethostname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the GPU name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using CUDAdrv\n",
    "@fetch CUDAdrv.name(CuDevice(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using CuArrays, BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch begin\n",
    "    A, B = rand(1000,1000), rand(1000,1000);\n",
    "    Agpu, Bgpu = CuArray(A), CuArray(B);\n",
    "    \n",
    "    println(\"Move array CPU -> GPU\")\n",
    "    @btime CuArray($A);\n",
    "    \n",
    "    println(\"A*B (cpu)\")\n",
    "    @btime $A * $B;\n",
    "\n",
    "    println(\"A*B (gpu)\")\n",
    "    @btime $Agpu * $Bgpu;\n",
    "    \n",
    "    \n",
    "    println(\"Move array GPU -> CPU\")\n",
    "    Cgpu = Agpu * Bgpu\n",
    "    @btime Array($Cgpu);\n",
    "    \n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch @eval using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trained = @fetch begin\n",
    "    m = Chain(\n",
    "    Dense(100, 10),\n",
    "    Dense(10, 5),\n",
    "    Dense(5, 2),\n",
    "    softmax # normalize output neurons\n",
    "    ) |> gpu\n",
    "    \n",
    "    data = rand(100, 100) |> gpu # fake data\n",
    "    labels = fill(0.5, 2, 100) |> gpu # fake data\n",
    "    \n",
    "    loss(x, y) = sum(Flux.mse(m(x), y)) # mean squared error\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    opt = Descent(0.01) # or ADAM\n",
    "    \n",
    "    Flux.train!(loss, params(m), [(data,labels)], opt)\n",
    "    \n",
    "    m |> cpu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trained(rand(100,100))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
